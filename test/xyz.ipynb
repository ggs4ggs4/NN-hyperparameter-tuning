{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes): #input_size 28*28 \n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features= input_size, out_features= 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "       x = F.relu(self.fc1(x))\n",
    "       \n",
    "       x = self.fc2(x)\n",
    "    #    print(x.shape)\n",
    "       return x\n",
    "model = NN(784, 10)\n",
    "data = torch.randn(64, 784)\n",
    "print(model(data).shape)\n",
    "# print(summary(model(data), input_size = data.shape))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 28*28\n",
    "batch_size = 64\n",
    "num_epochs= 1\n",
    "no_classes = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset load\n",
    "train_data = dataset.MNIST(root = 'dataset/', train = True, download = True, transform= transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset= train_data, batch_size= batch_size, shuffle= True)\n",
    "test_data = dataset.MNIST(root= 'dataset/', train = False, download= True, transform= transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset= test_data, batch_size= batch_size, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the network\n",
    "model = NN(input_size= input_size, num_classes= no_classes)\n",
    "# Loss and optimisers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params = model.parameters(), lr = learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.reshape(data.shape[0], -1) # (64, 1*28*28)\n",
    "        # forward pass\n",
    "        y = model(data)\n",
    "        loss = criterion(y, target)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from genetic import GeneticAlgorithm, Individual\n",
    "\n",
    "X, y = train_loader\n",
    "X_test, y_test = test_loader\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "hyperparameters = {\n",
    "\n",
    "    'learning_rate': np.logspace(-3, 0, 4)\n",
    "\n",
    "}\n",
    "\n",
    "# Define the fitness function\n",
    "def fitness_function(individual):\n",
    "    # Create a Gradient Boosted model with the individual's hyperparameters\n",
    "    # initialise the network\n",
    "    model = NN(input_size= input_size, num_classes= no_classes)\n",
    "    # Loss and optimisers\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(params = model.parameters(), lr = individual.genes['learning_rate'])\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    for epoch in range(individual.genes['epoch']):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.reshape(data.shape[0], -1) # (64, 1*28*28)\n",
    "            # forward pass\n",
    "            y = model(data)\n",
    "            loss = criterion(y, target)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient descent\n",
    "            optimizer.step()\n",
    "\n",
    "    # Predict the labels for the test data\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_loader:\n",
    "            scores = model(x)\n",
    "            \n",
    "    y_pred = model(X_test)\n",
    "    # Calculate the accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # Return the accuracy as the fitness value\n",
    "    return accuracy\n",
    "\n",
    "# Create the initial population\n",
    "population = [Individual(hyperparameters) for _ in range(100)]\n",
    "\n",
    "# Create the genetic algorithm\n",
    "ga = GeneticAlgorithm(population, fitness_function)\n",
    "\n",
    "# Run the genetic algorithm for 50 generations\n",
    "best_individual = ga.run(50)\n",
    "\n",
    "# Print the best individual's hyperparameters and fitness value\n",
    "print('Best Hyperparameters:', best_individual.genes)\n",
    "print('Best Fitness:', best_individual.fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
